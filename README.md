# ğŸ¦ AegisAI â€” Unified AI Observability & Governance Platform

## ğŸš¨ Problem

Modern banks use multiple AI systems:

- Traditional ML models â†’ credit scoring, fraud detection
- LLM systems â†’ chatbots, document processing, assistants

But these systems are monitored separately.
There is **no single place to understand AI risk**.

This creates:

- Model drift going unnoticed
- Hallucinated responses
- Compliance violations
- Financial & reputational damage

---

## ğŸ’¡ Our Solution

**AegisAI** provides a unified governance layer that continuously monitors ML + LLM systems and produces a real-time **AI Health Score**.

The platform detects risk before damage happens.

---

## ğŸ§  Key Features

### 1. ML Observability

- Detects model drift
- Tracks prediction accuracy
- Flags unreliable models

### 2. LLM Monitoring

- Measures latency
- Tracks token usage
- Detects unsafe responses

### 3. Governance Engine

- Combines ML + LLM risks
- Generates AI Health Score
- Classifies risk level

### 4. Unified Dashboard

- Single view of AI behavior
- Live risk alerts
- Explainable metrics

---

## ğŸ—ï¸ Architecture Flow

AI Systems â†’ Monitoring Layer â†’ Risk Engine â†’ Governance Score â†’ Dashboard

---

## âš™ï¸ Tech Stack

**Backend**

- FastAPI
- Python
- NumPy / Scikit-learn
- Uvicorn

**Frontend**

- Streamlit
- Plotly
- Pandas

**Deployment**

- Render (Backend)
- Streamlit Cloud (Frontend)

---

## â–¶ï¸ How To Run Locally

### Backend API

```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```

API Documentation: `http://127.0.0.1:8000/docs`

Available Endpoints:

- `GET /` â€” Health check
- `GET /api/ml-metrics` â€” ML monitoring metrics
- `GET /api/llm-metrics` â€” LLM monitoring metrics
- `GET /api/governance` â€” Combined governance score
- `GET /api/governance/detailed` â€” Detailed risk breakdown
- `GET /api/dashboard` â€” Complete system snapshot
- `POST /api/test/scenario/*` â€” Test scenarios (normal, drift, attack, critical)

### Frontend Dashboard

```bash
cd frontend
pip install -r requirements.txt
streamlit run dashboard.py
```

Dashboard URL: `http://localhost:8501`

---

## ğŸ“Š Dashboard Features

### Pages

**1. Executive Control Room (Overview)**

- Global Risk Indicator (LOW/MEDIUM/HIGH)
- 4 KPI Cards (Accuracy, Drift, Latency, Cost)
- Real-time accuracy trend chart
- Token usage distribution
- Active alerts feed

**2. ML Observability**

- Model drift gauge
- Accuracy, precision, recall trends
- Bias score indicator
- Latency monitoring
- Recent predictions table

**3. LLM Observability**

- Hallucination rate gauge
- Safety compliance score
- Token usage & cost tracking
- Daily cost accumulation
- LLM interaction logs

**4. Governance & Responsible AI**

- Active alerts & incidents
- Compliance dashboard
- Risk heatmap by component
- Human-in-the-loop metrics
- Compliance controls documentation

### Simulation Controls (Sidebar)

Toggle to test scenarios:

- **ML Drift** â€” Simulates model degradation
- **LLM Hallucination** â€” Simulates unsafe responses
- **High Token Cost** â€” Simulates cost spike
- **Safety Incident** â€” Triggers compliance alerts

---

## ğŸ¯ Key Scenarios

### Normal Operation

All systems healthy, metrics within normal ranges.

### ML Drift Detected

- Accuracy drops below 80%
- Drift score exceeds 50%
- Status: "High Risk"
- Action: Review retraining

### LLM Hallucination Spike

- Hallucination rate > 20%
- Safety flag triggered
- Status: "Unsafe"
- Action: Immediate escalation

### Critical (Combined)

Both ML drift AND LLM attack occur simultaneously.
Risk level: **CRITICAL - GOVERNANCE ACTION REQUIRED**

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ML + LLM Systems (Banking)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”
    â”‚ ML     â”‚           â”‚ LLM       â”‚
    â”‚Monitor â”‚           â”‚ Monitor   â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Risk Engine     â”‚
            â”‚ (Governance)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ FastAPIâ”‚           â”‚ Streamlit  â”‚
    â”‚ Backendâ”‚           â”‚ Dashboard  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Responsible AI Features

âœ… **Real-time Bias Monitoring** â€” Detects fairness issues across demographics

âœ… **Hallucination Detection** â€” Automatically flags unsafe LLM responses

âœ… **Safety Compliance** â€” Enforces governance rules and policies

âœ… **Audit Logging** â€” Complete trace of all AI decisions

âœ… **Human-in-the-Loop** â€” Critical decisions require human approval

âœ… **Explainability** â€” Model decisions are transparent and traceable

---

## ğŸ“ˆ Performance Metrics

The dashboard tracks:

**ML Metrics:**

- Accuracy, Precision, Recall
- Model Drift (PSI)
- Bias Score
- Latency

**LLM Metrics:**

- Response Latency
- Token Usage & Cost
- Hallucination Rate
- Safety Compliance Score
- Throughput (requests/min)

**Governance:**

- AI Health Score (0-100)
- Risk Level (STABLE â†’ MONITORING â†’ ELEVATED â†’ CRITICAL)
- Active Alerts
- Compliance Status

---

## ğŸš€ Deployment

### Backend

```bash
# Using Render
git push render main
```

### Frontend

```bash
# Using Streamlit Cloud
Connect GitHub repo â†’ Deploy
```

---

## ğŸ“ Project Structure

```
AegisAI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ llm_monitor.py          # LLM metrics generation
â”‚   â”œâ”€â”€ ml_monitor.py           # ML metrics generation
â”‚   â”œâ”€â”€ risk_engine.py          # Governance & risk scoring
â”‚   â””â”€â”€ requirements.txt         # Backend dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ dashboard.py            # Streamlit app
â”‚   â””â”€â”€ requirements.txt         # Frontend dependencies
â””â”€â”€ README.md                   # This file
```

---

## ğŸ¯ Demo Scenario

1. **Baseline**: System starts in healthy state (All metrics green)
2. **Trigger Drift**: Check "ML Drift" toggle in sidebar
3. **Monitor**: Watch accuracy drop, drift score rise
4. **Alert**: Red alerts appear in feed, risk indicator turns HIGH
5. **Escalate**: Governance page shows escalation needed
6. **Resolve**: Uncheck toggle, watch recovery

This demonstrates end-to-end AI governance in action.

---

## ğŸ‘¥ Team

Built with intention â€” AegisAI Team

Enterprise-grade AI Governance Platform for Banking.
